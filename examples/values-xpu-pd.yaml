# Example values for Intel XPU with Prefill/Decode disaggregation
# This configuration demonstrates P/D disaggregation on Intel XPU

modelArtifacts:
  name: microsoft/DialoGPT-large
  uri: "hf://microsoft/DialoGPT-large"
  size: 10Gi

# Configure accelerator for Intel XPU
accelerator:
  type: intel
  resources:
    intel: "gpu.intel.com/i915"
  env:
    intel:
      - name: ZE_ENABLE_PCI_ID_DEVICE_ORDER
        value: "1"
      - name: SYCL_DEVICE_FILTER
        value: "gpu"

routing:
  servicePort: 8000
  proxy:
    image: ghcr.io/llm-d/llm-d-routing-sidecar:v0.2.0
    targetPort: 8200
    # Use compatible connector for XPU
    connector: nixlv2

  parentRefs:
  - group: gateway.networking.k8s.io
    kind: Gateway
    name: inference-gateway
    namespace: "{{ .Release.Namespace }}"
  
  httpRoute:
    create: true
    matches:
      - path:
          type: PathPrefix
          value: /
        headers:
        - name: x-model-name
          type: Exact
          value: "{{ .Values.modelArtifacts.name }}"

  epp:
    create: true
    image: ghcr.io/llm-d/llm-d-inference-scheduler:v0.2.1
    # Use XPU-compatible configuration
    pluginsConfigFile: "default-config.yaml"

# Decode pod configuration for Intel XPU
decode:
  create: true
  replicas: 1
  containers:
  - name: "vllm"
    image: "ghcr.io/llm-d/llm-d-xpu:v0.2.0"
    modelCommand: vllmServe
    args:
      - "--device"
      - "xpu"
      - "--enforce-eager"
      - "--kv-transfer-config"
      - '{"kv_connector":"XPUConnector", "kv_role":"kv_both"}'
    env:
      - name: INTEL_GPU_VISIBLE_DEVICES
        value: "0"
      - name: ZE_ENABLE_PCI_ID_DEVICE_ORDER
        value: "1"
      - name: VLLM_NIXL_SIDE_CHANNEL_HOST
        valueFrom:
          fieldRef:
            fieldPath: status.podIP
      - name: VLLM_NIXL_SIDE_CHANNEL_PORT
        value: "5557"
      - name: VLLM_LOGGING_LEVEL
        value: DEBUG
    ports:
      - containerPort: 8200
        protocol: TCP
      - containerPort: 5557  # NIXL side channel
        protocol: TCP
    resources:
      limits:
        memory: 32Gi
        cpu: "16"
        intel.com/gpu: "1"
      requests:
        cpu: "8"
        memory: 16Gi
        intel.com/gpu: "1"
    mountModelVolume: true

  acceleratorTypes:
    labelKey: "accelerator"
    labelValues:
      - "intel-xpu"

# Prefill pod configuration for Intel XPU
prefill:
  create: true
  replicas: 1
  containers:
  - name: "vllm"
    image: "ghcr.io/llm-d/llm-d-xpu:v0.2.0"
    modelCommand: vllmServe
    args:
      - "--device"
      - "xpu"
      - "--enforce-eager"
      - "--kv-transfer-config"
      - '{"kv_connector":"XPUConnector", "kv_role":"kv_both"}'
    env:
      - name: INTEL_GPU_VISIBLE_DEVICES
        value: "0"
      - name: ZE_ENABLE_PCI_ID_DEVICE_ORDER
        value: "1"
      - name: VLLM_NIXL_SIDE_CHANNEL_PORT
        value: "5557"
      - name: VLLM_NIXL_SIDE_CHANNEL_HOST
        valueFrom:
          fieldRef:
            fieldPath: status.podIP
      - name: VLLM_LOGGING_LEVEL
        value: DEBUG
    ports:
      - containerPort: 8000
        protocol: TCP
      - containerPort: 5557
        protocol: TCP
    resources:
      limits:
        memory: 32Gi
        cpu: "16"
        intel.com/gpu: "1"
      requests:
        cpu: "8"
        memory: 16Gi
        intel.com/gpu: "1"
    mountModelVolume: true

  acceleratorTypes:
    labelKey: "accelerator"
    labelValues:
      - "intel-xpu"

multinode: false
